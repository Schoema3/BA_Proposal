\documentclass[journal]{IEEEtran}
%\hyphenation{op-tical net-works semi-conduc-tor}

\usepackage{ae}
\usepackage{aecompl}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel} % oder \usepackage[ngerman]{babel}

\usepackage{amssymb, amsmath}
\usepackage[caption=false ,font=footnotesize]{subfig}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf} 
\usepackage{hyperref}
\usepackage{alltt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%\title{Parallel Tasklets for Many-Core Architectures}
%\title{Exploring efficient concurrency and locality control mechanisms for parallel tasklets}% execution model}% for Many-Core
%\title{Accelerating parallel tasklets through efficient concurrency and locality control}% execution model}% for Many-Core Architectures}
%\title{Enabling parallel tasklets execution through efficient concurrency and locality control}% execution model}% for Many-Core Architectures}
\title{High-throughput task parallelism with concurrency~and~locality control}
\author{Mein Name\protect\\\texttt{Mein.Name@tu-cottbus.de}}
\maketitle

\begin{itshape}
  Ein geeignetes Thema für die eigene Abschlussarbeit zu finden kann
  sehr zeitaufwendig sein.  Dieses Dokument enthält eine Vorlage für
  die Vorbereitung auf ein Arbeitsthema. Diese kursiv gesetzen
  Textabschnitte können später entfernt werden.

  In der Regel werden Themen oder Ideen durch die Betreuer
  vorgeschlagen.  Allerdings befreit dies nicht davon, das eigene
  Thema und die eigene Aufgabenstellung selbst zu verstehen.  Eine
  Strategie um späteren Überraschungen vorzubeugen ist, die
  Aufgabenstellung und eine Einführung in das Thema selbst schriftlich
  auszuarbeiten -- natürlich mit Unterstützung durch die Betreuer.
  
  Dein Inhalt in diesem Dokument wird sicherlich mehrmals überarbeitet
  werden. Deshalb keine Angst: Nur fehlendes Material ist schlechtes
  Material! Eine Seite Text für Zusammenfassung+Einleitung ist
  ausreichend.
\end{itshape}

\begin{abstract}
  \textit{1) Was ist das Problem?}
  The parallel execution of tasks requires reasonable concurrency and
  locality control.
  \textit{2) Warum ist das Problem interessant?}
  To achieve high throughput on many-core architectures, their high
  number of hardware threads has to be utilized due to a low
  instruction throughput of individual hardware threads.
  Consequently, parallel execution with efficient control mechanisms
  is crucial.
  \textit{3) Was will ich in der Arbeit machen?}
  This thesis explores efficient concurrency and locality control
  mechanisms for a parallel task execution model and evaluates
  implementation variants.
  \textit{4) Welches Ergebnis wird angestrebt?}
  The evaluation shows that thread groups for locality control
  combined with delegation queues for concurrency control provide a
  significant improvement over a static assignment of task to specific
  hardware threads.
\end{abstract}

\begin{IEEEkeywords}
many-core, event-driven, asynchronous, concurrency, locality, tasklet
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction/Einleitung}
\begin{itshape}
  Die Einleitung wiederholt die Zusammenfassung von oben. Hier ist nun
  mehr Platz für Begründungen, Erklärungen, Begriffsdefinitionen und
  Literaturverweise.  

  1--2) Was ist das Problem? Welches Anwendungsgebiet wird betrachtet?
  Warum ist eine Problemlösung interessant? Für wen?
\end{itshape}

\noindent Many-Core Architectures (MCAs) provide a large number of
``low frequency, low complexity cores'' \cite[p. 27]{vajda2011}: high
frequencies would lead to over-proportional higher power consumption
\cite[p. 2]{vajda2011}; the space of complex cores can be traded for a
higher number of simple cores \cite{challengesMCC}. In consequence,
the instruction throughput of a single thread is low and high
performance can be achieved only through parallelism.

To compensate for the lower instruction throughput, MCAs often provide
parallelism on the instruction level (SIMD) and application-specific
CPU extensions.
%
Not every task can profit from this kind of acceleration; this is
especially true for resource management tasks found, for example, in
operating systems and middleware.  Thus, the overhead generated by
resource management on MCAs may take a larger share of the runtime
even in single threaded applications.

However, applications are expected to be highly concurrent in order to
exploit the large number of threads provided by MCAs.  Ideally, the
scalability of such applications should not be limited by slow,
sequential resource management tasks.  Conclusively, support for
parallelism on the task level is needed.

Unfortunately, not every set of tasks can be parallelized
effortlessly: shared resources may only support certain kinds of
concurrent access or even no concurrent access at all.
%
Concurrency control subsumes all mechanisms that enable obtaining
correct results in concurrent programs; it includes mutual exclusion
as well as optimistic transaction-based mechanisms.

Another factor becoming more important when dealing with MCAs is the
placement of tasks relative to resources. Some resources are
accessible only by certain threads (a specific cache or TLB), whereas
other resources are accessible by all threads but the access costs
depend on the thread (NUMA, data in caches).
%
Analogously to concurrency control, locality control is used here to
subsume all mechanisms that allow to specify where a task can be
executed. This includes assigning each task to a specific thread as
well as more abstract mechanisms like executing a task on any thread
of an arbitrary chosen group.

\begin{itshape}
  3) Was will ich in der Arbeit machen?  Welchen Aspekt des Problems
  will ich lösen? Was ist die grobe Lösungsidee?  Welche Aspekte
  sollen/müssen nicht behandelt werden?
\end{itshape}

In this thesis, existing task parallel programming models will be
examined with a focus on concurrency and locality control mechanisms.
Based on the results, a programming model using parallel tasklets will
be developed.
%
Tasklets are lightweight tasks which can not be suspended and run to
completion.  However, more complex task representations can easily be
implemented on top of
tasklets.
%
The model provides thread groups as a locality control mechanism, that
enforce hard locality constraints but also allows implementations to
employ online algorithms for dynamic work sharing in order to improve
the task throughput.  Moreover, the model includes concurrency control
mechanisms which enable common synchronization patterns as well as
sophisticated parallel algorithms.

\begin{itshape}
  4) Was soll erreicht werden? Wie soll dies experimentell
  nachgewiesen werden?
\end{itshape}

In order to examine the implications of the parallel execution of
tasklets within thread groups, the model will be implemented in C++11.
Primarily, the parallel execution of tasks with shared resources will
be evaluated against controlling concurrency and locality by
statically assigning tasks to individual threads; secondarily,
implementation variants for work sharing and mutual exclusion will be
evaluated.

\begin{itshape}
  5) Was wird durch meine Lösung vermutlich möglich? (in Bezug auf das
  gesamte Thema und eventuell darüber hinaus) 
\end{itshape}

It is expected that the parallel tasklet model is well-suited to
increase the parallelism of tasks by providing reasonable concurrency
control mechanisms and allowing implementations to employ efficient
work sharing algorithms. Delegation locking, a locality-aware locking
mechanism, is expected to improve the performance of lock-based
synchronization further.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Domain Analysis / Stand der Technik}
\begin{itshape}
  Welche Aspekte des Problems sind vermutlich schon gelöst? Welche
  Publikationen behandeln welches Teilproblem? Zu welchen
  Teilproblemen wurde keine Literatur gefunden?  Hier wird eine
  kompakte Übersicht über den Stand der Technik benötigt. Dabei geht
  es noch nicht um detaillierte Inhalte der Publikationen sondern um
  ihre grobe Einordnung. Dazu genügt es in der Regel, die Abstracts
  und die Conclusions am Ende der Artikel zu lesen. Dieses Kapitel
  wird später das wichtigste der schriftlichen Ausarbeitung, denn es
  ist für die Einordnung der eignen Ergebnisse und Erfolge notwendig.
\end{itshape}

\begin{itemize}
\item locality: caches, NUMA, consistency islands, distributed memory systems
\item programming models: fork/join (Cilk+, OpenMP 4 Tasks), futures
  (Rust, Taco), event-based (node.js, libevent), thread
  synchronization primitives, Linux kernel tasklets, TinyOS, CSP
  (rust/go/StacklessPhython channels), Ada rendevous+monitor, Apple
  Grand Central Dispatch, Actor Models, Chapel, X10
\item stackless execution: continuation passing, protothreads
\item flat and hierarchical workstealing
\item mutex implementations: flat combining, delegation locks, spinlocks. procedure chaining
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Concept / Lösungsansatz}
\begin{itshape}
  Wie sieht die Lösungsidee grob aus? Zum Beispiel: Welche Modelle,
  Datenstrukturen, Algorithmen, oder Software-Komponenten müssen
  entwickelt werden? Welche bekannten Lösungen sollen übertragen
  werden? Das zweitwichtigste Kapitel der späteren Ausarbeitung.
\end{itshape}

\begin{itemize}
\item Design Criteria: light-weight, concurrent execution of task,
  building blocks for concurrency control that allow easy
  implementation of typical synchronization pattern (monitor,
  reader/writer) but also allows for sophisticated algorithms
  (lock-/wait-free algorithms)
\item locality control: Thread groups as shared task queues. Any
  thread of a group can dequeue and process tasks from the group's
  queue. Enforce strict locality constraints. Match NUMA
  locality. Threads can be in multiple groups.
\item concurrency control: Mutexes by delegation queues and
  combiner. Tasks that failed to acquire a mutex are enqeued at the
  mutex. When releasing a mutex, next waiting enqueued task is
  activated. 
\item usage examples: Monitor, Reader/Writer locks, light-weight
  fork/join, Coroutines, nested locks, condition variables
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation}
\begin{itshape}
  Was ist notwendig, um einen Prototypen für die Evaluation und
  Bewertung der Lösung zu erreichen? Was kann dafür weggelassen
  werden? Was muss für die Umsetzung des Konzeptes programmiert
  werden?
\end{itshape}

\begin{itemize}
\item Mapping of the concept to a C++11 interface
\item implement tasklets, queues, locking mechanisms
\item implementation variants: shared MWMR queues, non-hierarchical
  workstealing, hierarchical workstealing, pseudo groups with single
  thread
\item functionality tests and benchmark applications: fibonacci
  function, fork-join multicast, shared atomic increment object,
  \ldots
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation}
\begin{itshape}
  Welche Experimente, Messungen, Vergleiche sind notwendig, um eine
  Lösung im Vergleich zu anderen Lösungen zu bewerten?  Welche
  Hypothesen sollen belegt bzw. widerlegt werden? Was wird benötigt um
  diese Experimente durchführen zu können?
\end{itshape}

Main question: are task groups better than static thread binding? How
many threads can go into one group. Implementation variants are
evaluated against each other: Delegation Queues against naive
implementation; work Stealing against naive implementations.
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}
\begin{itshape}
  Kurzzusammenfassung: Was wurde gemacht? Was kam dabei raus? Was wird
  dadurch möglich? Welche Fragen und Probleme können auf dieser
  Grundlage als nächstes untersucht werden?
\end{itshape}

The chosen execution model provide a solid foundation for efficient
concurrent systems on many-core architectures. Concurrent task
execution on shared resources has been shown to be advantageous
compared to sequentialization on fixed hardware threads.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%% bibliography

%\nocite{*}
\bibliographystyle{IEEEtran}
\bibliography{literature}
%\bibliography{IEEEabrv,literature}

\end{document}